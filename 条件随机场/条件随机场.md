# 条件随机场

# 概率无向图

概率无向图又称为马尔可夫随机场，它是一个联合概率分布，可以形象化地由无向图表示。

## 概率无向图的定义

图是由结点v和连接结点的边e组成的集合（如果了解数据结构，对图的概念会更清楚），结点和边的集合为V和E，整个图为$G=(V, E)$。图可以是有向的，也可以是无向的，有向指连接结点的边有方向的属性，而无向是指边没有方向的属性。

概率图模型是由图表示的概率分布。设有联合概率分布$P(Y)$，$Y\in \gamma$是一组随机变量，由无向图$G=(V，E)$表示概率分布$P(Y)$，即在图G中，结点$v \in V$表示一个随机变量$Y_v$，$Y=(Y_v)_{v \in V}$;边$e \in E$表示随机变量之间的概率依赖关系。

概率无向图的随机变量之间有成对马尔可夫性，局部马尔可夫性和全局马尔可夫性。

* 成对马尔可夫性

  设和$v$是无向图$G$中任意两个没有边连接的结点，结点$u$和$v$分别对应随机变量$Y_u$,和$Y_v$。其他所有结点为$O$,对应的随机变量组是$Y_O$。成对马尔可夫性是指给定随机变量组$Y_O$的条件下随机变量$Y_u$和$Y_v$是条件独立的，即
  $$
  P\left(Y_{u}， Y_{v} \mid Y_{o}\right)=P\left(Y_{u} \mid Y_{o}\right) P\left(Y_{v} \mid Y_{o}\right)
  $$

* 局部马尔可夫性

  局部马尔可夫性：设$v\in V$是无向图$G$中任意一个结点，$W$是与$v$有边连接的所有结点，$O$是$v$，$W$以外的其他所有结点。$v$表示的随机变量是$Y_v$，$W$表示的随机变量组是$Y_W$，$O$表示的随机变量组是$Y_O$。局部马尔可夫性是指在给定随机变量组$Y_W$的条件下随机变量$Y_v$与随机变量组$Y_O$。是独立的，即
  $$
  P\left(Y_{v}， Y_{o} \mid Y_{W}\right)=P\left(Y_{v} \mid Y_{W}\right) P\left(Y_{O} \mid Y_{W}\right)
  $$
  在$P(Y_O|Y_W) > 0 $时，等价，
  $$
  P(Y_O|Y_W) = P\left(Y_{v}， Y_{o} \mid Y_{W}\right)
  $$

* 全局马尔可夫性

  全局马尔可夫性:设结点集合$A，B$是在无向图G中被结点集合C分开的任意结点集合，如下图所示,结点集合$A，B$和$C$所对应的随机变量组分别是$Y_A$和$Y_C$。全局马尔可夫性是指给定随机变量组$Y_C$条件下随机变量组$Y_A$和$Y_B$是条件独立的，即
  $$
  P\left(Y_{A}， Y_{B} \mid Y_{C}\right)=P\left(Y_{A} \mid Y_{C}\right) P\left(Y_{B} \mid Y_{C}\right)
  $$
  

  ![image-20240229180522913](.\images\11.2.png)

## 因子分解

给定概率无向图模型，设其无向图为$G$，$C$为$G$上的最大团，$Y_C表示$$C$对应的随机变量。那么概率无向图模型的联合概率分布$P(Y)$可写作图中所有最大团$C$上的函数$\Psi_{C}\left(Y_{C}\right)$的乘积形式，即
$$
P(Y)=\frac{1}{Z} \prod_{c} \Psi_{C}\left(Y_{C}\right) 
$$
其中Z是规范化因子：
$$
Z=\sum_{Y} \prod_{C} \Psi_{C}\left(Y_{C}\right) 
$$
为了保证$P(Y)$为概率。 $\Psi_{C}\left(Y_{C}\right)$为势函数，要求势函数必须为正，即严格正的，因此势函数通常使用指数函数：
$$
\Psi_{C}\left(Y_{C}\right)=\exp \left\{-E\left(Y_{C}\right)\right\} 
$$


# 条件随机场

条件随机场是给定随机变量X条件下，随机变量Y的马尔可夫随机场。条件随机场有非常多的形式，这里主要介绍定义在线性链上的特殊的条件随机场，称为线性链条件随机场。

线性链条件随机场用于标注问题，在条件概率模型$P(Y|X)$中，Y是输出变量，表示标记序列，也称为状态序列。$X$是输入变量，表示需要标注的观测序列。学习时，利用训练数据集通过极大似然估计或正则化的极大似然估计得到条件概率模型${\hat P}(Y \mid X) $。预测时，对于给定的输入序列x，求出条件概率${\hat P}(Y \mid X) $ 最大的输出序列$\hat{y}$。

设X与Y是随机变量，$P(Y|X)$是在给定X的条件下$Y$的条件概率分布。若随机变量$Y$构成一个由无向图$G=(V, E)$表示的马尔可夫随机场：
$$
P\left(Y_{v} \mid X， Y_{w}， \quad w \neq v\right)=P\left(Y_{v} \mid X， Y_{w}， w \sim v\right)
$$
对任意结点v成立，则称条件概率分布$P(Y|X)$为条件随机场。式中w≠v表示结点v以外的所有结点，$w\ne v$表示在图$G=(V, E)$中与结点$v$有边连接的所有结点$w$。

在定义中并没有要求X和Y具有相同的结构。现实中，一般假设X和Y有相同的图结构。我们主要考虑的线性链情况如下：

![image-20240229200030792](.\images\11.5.png)

可以用下式表述上面的两种情况：
$$
G=(V=\{1，2， \cdots， n\}， E=\{(i， i+1)\})， i=1，2， \cdots， n-1 
$$
容易理解，$V$是图$G$中的所有结点的集合，$E$是所有边的集合，每个边使用该边连接的两个点来表示，比如对于结点1和2，连接它们的边为$(1, 2)$，显然，在上图的两种情况中，$E={(1, 2), (2, 3), \cdots , (n-1, n)}$。

这样，就可以对线性链条件随机场做一个数学上的定义了：

设$X=(X1,X2,\cdots ,Xn),Y=(Y1,Y2,\cdots ,Yn)$均为线性链表示的随机变量序列，若在给定随机变量序列X的条件下，随机变量序列Y的的条件概率分布$P(Y|X)$构成条件随机场，即满足马尔可夫性：
$$
P\left(Y_{i} \mid X， Y_{1}， \cdots， Y_{i-1}， Y_{i+1}， \cdots， Y_{n}\right)=P\left(Y_{i} \mid X， Y_{i-1}， Y_{i+1}\right) 
$$

$$
i=1，2， \cdots， n( 在 i=1  时只考虑单边 ) 
$$

在标注问题中，X表示输入观测序列，Y表示对应的输出标记序列或状态序列。



## 条件随机场的参数化形式

根据计算条件随机场的联合概率公式：
$$
P(Y)=\frac{1}{Z} \prod_{c} \Psi_{C}\left(Y_{C}\right) \\\Psi_{C}\left(Y_{C}\right)=\exp \left\{-E\left(Y_{C}\right)\right\}
$$
可以推得在随机变量X取值为x的条件下，随机变量Y取值为y的条件概率：
$$
P(y \mid x)=\frac{1}{Z(x)} \exp \left(\sum_{i， k} \lambda_{k} t_{k}\left(y_{i-1}， y_{i}， x， i\right)+\sum_{i， l} \mu_{l} s_{l}\left(y_{i}， x， i\right)\right) 
$$
其中$t_k$是定义在无向边上的特征函数，称为转移特征，依赖于当前和前一个位置。$s_l$是定义在结点上的特征函数，称为状态特征，依赖于当前位置。$t_k$和$s_l$都依赖于位置，是局部特征函数。通常，特征函数$t_k$和$s_l$取值为1或0，当满足特征条件时取值为1，否则为0。条件随机场完全由特征函数$t_k$，$s_l$和对应的权值$\lambda_k$，$\mu_l$确定。



## 条件随机场的简化形式：

思想就是将转移特征和状态特征合并，使用一个统一的符号表示，将转移特征的权值和状态特征的权值合并，使用一个统一的符号表示，接着将两者进行内积计算即可。

设有K个转移特征，$K_2$个状态特征，则$K=K1+K2$。

将转移特征和状态特征合并，使用一个统一的符号表示：
$$
f_{k}\left(y_{i-1}， y_{i}， x， i\right)=\left\{\begin{array}{ccc}t_{k}\left(y_{i-1}， y_{i}， x，i \right)， & k=1，2， \cdots， K_{1} \\ s_{l}\left(y_{i}， x， i\right)， & k=K_{1}+l ； l=1， 2， \cdots， K_{2}\end{array}\right.
$$
然后，对转移与状态特征在各个位置求和：
$$
f_{k}(y， x)=\sum_{i=1}^{n} f_{k}\left(y_{i-1}， y_{i}， x， i\right)， k=1，2， \cdots， K 
$$
将转移特征的权值和状态特征的权值合并，使用一个统一的符号表示：
$$
w_{k}=\left\{\begin{array}{lr}\lambda_{k}， & k=1，2， \cdots， K_{1} \\ \mu_{l}， & k=K_{1}+l ； l=1，2， \cdots， K_{2}\end{array}\right.
$$
接着将两者进行内积计算，就得到了条件随机场的简化形式：
$$
P(y \mid x)=\frac{1}{Z(x)} \exp \sum_{k=1}^{K} w_{k} f_{k}(y， x) 
$$
## 条件随机场的矩阵形式

引进特殊的起点和终点状态标记，$y_0=start，y_{n+1}=stop$。

对观测序列x的每一个位置$i=1,2,\cdots,n+1,$定义一个m阶矩阵(m是标记$y_i$取值的个数)
$$
M_{i}(x)=\left[M_{i}\left(y_{i-1}， y_{i} \mid x\right)\right] \\
M_{i}\left(y_{i-1}， y_{i} \mid x\right)=\exp \left(W_{i}\left(y_{i-1}， y_{i} \mid x\right)\right) \\
W_{i}\left(y_{i-1}， y_{i} \mid x\right)=\sum_{k=1}^{K} w_{k} f_{k}\left(y_{i-1}， y_{i}， x， i\right) 
$$
这样，给定观测序列$x$，标记序列$y$的非规范化概率可以通过$n+1$个矩阵的乘积$\prod_{i=1}^{n+1}M_i(y_{i=1},y_i|x)$表示，于是，条件概率$P_w(y|x)$是
$$
P_{w}(y \mid x)=\frac{1}{Z_{w}(x)} \prod_{i=1}^{n+1} M_{i}\left(y_{i-1}， y_{i} \mid x\right)
$$
其中Z为：
$$
Z_{w}(x)=\left[M_{1}(x) M_{2}(x) \cdots M_{n+1}(x)\right]_{\text {start,stop}}  
$$

# 概率计算问题

条件随机场的概率计算问题是给定条件随机场$P(Y|X)$，输入序列x和输出序列y，计算条件概率$P\left(Y_{i}=y_{i} \mid x\right)，P\left(Y_{i-1}=y_{i-1}，Y_{i}=y_{i} \mid x\right) $以及相应的数学期望的问题。

## 前向-后向算法

对每个指标$i=0, 1, \cdots, n+1$，定义前向向量$α_i(x)$：
$$
a_{0}(y \mid x)=\left\{\begin{array}{lr}1， & y=\text { start } \\ 0， & \text { 否则 }\end{array}\right. 
$$
递推公式：
$$
a_{i}^{\mathrm{T}}\left(y_{i} \mid x\right)=\alpha_{i-1}^{\mathrm{T}}\left(y_{i-1} \mid x\right)\left[M_{i}\left(y_{i-1}， y_{i} \mid x\right)\right]， \quad i=1，2， \cdots， n+1 
$$
也可表示为：
$$
a_{i}^{\mathrm{T}}(x)=\alpha_{i-1}^{\mathrm{T}}(x) M_{i}(x)
$$
$a_{i}\left(y_{i} \mid x\right)$表示位置为i，且位置i的标记为$y_i$，并且从1到i的前部分标记序列的非规范化概率。比如从1到4的标记为(1, 2, 2, 1)，那么$a_4(1|x)$，即在第四个位置，$y_4=1$，且$y_1=1$, $y_2=2$, $y_3=2$, $y_4=1$的非规范化概率。

注意在上式的等号右边 ，$ M_{i}\left(y_{i-1}， y_{i} \mid x\right)$ 是矩阵中的一个元素，而非矩阵本身。$a_1$显然为第一个矩阵中的一个元素，因此每一个$a_i$都是由从1到i，一共i个矩阵中的某个元素相乘得到的，使用的矩阵中某个元素的位置由$y(i-1)$和$y_i$的值确定。

对每个指标$i=0, 1, \cdots, n+1$，定义后向概率：
$$
\beta_{n+1}\left(y_{n+1} \mid x\right)=\left\{\begin{array}{cc}1， & y_{n+1}=\text { stop } \\ 0， & \text { 否则 }\end{array}\right. 
$$
递推公式
$$
\beta_{i}\left(y_{i} \mid x\right)=\left[M_{i+1}\left(y_{i}， y_{i+1} \mid x\right)\right] \beta_{i+1}\left(y_{i+1} \mid x\right) 
$$
也可表示为：
$$
\beta_{i}(x)=M_{i+1}(x) \beta_{i+1}(x)
$$
后向概率是由i+1到n的后部分标记序列的非规范化概率。比如从1到4的标记为(1, 2, 2, 1)，那么$\beta_{2}(2|x)$为，在第2个位置，$y_2=2$，且$y_3=2$, $y_4=1$的非规范化概率，同样由各个对应矩阵中的元素相乘得到。

那么在位置i，其标记为$y_i$的条件概率为：
$$
P\left(Y_{i}=y_{i} \mid x\right)=\frac{\alpha_{i}^{\mathrm{T}}\left(y_{i} \mid x\right) \beta_{i}\left(y_{i} \mid x\right)}{Z(x)} 
$$
在位置$i-1$与$i$，两个位置的标记为$y(i-1)$和$y_i$的条件概率为：
$$
P\left(Y_{i-1}=y_{i-1}， Y_{i}=y_{i} \mid x\right)=\frac{\alpha_{i-1}^{\mathrm{T}}\left(y_{i-1} \mid x\right) M_{i}\left(y_{i-1}， y_{i} \mid x\right) \beta_{i}\left(y_{i} \mid x\right)}{Z(x)} 
$$
其中
$$
Z(x)=\alpha_{n}^{\mathrm{T}}(x) \mathbf{1}=\mathbf{1} \beta_{1}(x)
$$
$1$是元素均为1的m维列向量。

# 学习问题

## 改进的迭代尺度法

在使用IIS之前，我们首先需要得到训练数据的对数似然函数：
$$
L(w)=L_{p}\left(P_{w}\right)=\log \prod_{x， y} P_{w}(y \mid x)^{\tilde{P}(x， y)}=\sum_{x， y} \tilde{P}(x， y) \log P_{w}(y \mid x) 
$$
对条件随机场：
$$
f_{k}(y， x)=\sum_{i=1}^{n} f_{k}\left(y_{i-1}， y_{i}， x， i\right)， k=1，2， \cdots， K  \\w_{k}=\left\{\begin{array}{lr}\lambda_{k}， & k=1，2， \cdots， K_{1} \\ \mu_{l}， & k=K_{1}+l ； l=1，2， \cdots， K_{2}\end{array}\right.  \\P(y \mid x)=\frac{1}{Z(x)} \exp \sum_{k=1}^{K} w_{k} f_{k}(y， x) 
$$
对数似然函数为：
$$
\\ L(w)=\sum_{x， y} \tilde{P}(x， y) \log P_{w}(y \mid x) \\=\sum_{x， y} \tilde{P}(x， y) \log \left(\frac{1}{Z(x)} \exp \sum_{k=1}^{K} w_{k} f_{k}(y， x)\right) \\ =\sum_{x， y}\left[\tilde{P}(x， y) \sum_{k=1}^{K} w_{k} f_{k}(y， x)-\tilde{P}(x， y) \log Z_{w}(x)\right]
$$
假设模型的当前参数向量为：$w=\left(w_{1}， w_{2}， \cdots， w_{K}\right)^{\mathrm{T}} $，每次迭代的更新量为：$\delta=\left(\delta_{1}， \delta_{2}， \cdots， \delta_{K}\right)^{\mathrm{T}}  $，这样，我们就可以通过IIS方法，在迭代中更新其下界，使对数似然函数极大化。

在IIS方法中，我们在对每一个更新量求导并令导数为0，得到的一般形式的公式为：
$$
E_{P}^{\sim}\left(f_{i}\right)=\sum_{x， y} \tilde{P}(x， y) f_{i}(x， y)=\sum_{x} \tilde{P}(x) \sum_{y} P_{w}(y \mid x) f_{i}(x， y) \exp \left(\delta_{i} f^{\#}(x， y)\right) 
$$
因为在线性链条件随机场中有两个特征函数（转移特征$t_k$和状态特征$s_l$），我们将这两个特征函数分别代入上式中：
$$
E_{P}^{\sim}\left[t_{k}\right]=\sum_{x， y} \tilde{P}(x， y) \sum_{i=1}^{n+1} t_{k}\left(y_{i-1}， y_{i}， x， i\right)  \\=\sum_{x， y} \tilde{P}(x) P(y \mid x) \sum_{i=1}^{n+1} t_{k}\left(y_{i-1}， y_{i}， x， i\right) \exp \left(\delta_{k} T(x， y)\right)  \\ k=1，2， \cdots， K_{1} 
$$

$$
E_{\tilde{p}}\left[s_{l}\right]=\sum_{x， y} \tilde{P}(x， y) \sum_{i=1}^{n+1} s_{l}\left(y_{i}， x， i\right) \\
\sum_{x， y} \tilde{P}(x) P(y \mid x) \sum_{i=1}^{n} s_{l}\left(y_{i}， x， i\right) \exp \left(\delta_{K_{1}+l} T(x， y)\right) \\
l=1，2， \cdots， K_{2}
$$

其中$T(x, y)$对应于IIS中的$f_k(x, y)$，但在这里是数据(x, y)中出现的所有特征数的总和：
$$
T(x， y)=\sum_{k} f_{k}(y， x)=\sum_{k=1}^{K} \sum_{i=1}^{n+1} f_{k}\left(y_{i-1}， y_{i}， x， i\right) 
$$
T(x, y)中的x和y是一个实例的数据，k是不同的特征函数，不同的特征函数有不同的规则。

因为不同的实例所拥有的数据不同，因此不同的实例的T(x, y)的值不同，我们可以定义一个松弛特征来解决这个问题：
$$
s(x， y)=S-\sum_{i=1}^{n+1} \sum_{k=1}^{K} f_{k}\left(y_{i-1}， y_{i}， x， i\right) 
$$
S是一个常数，选择足够大的常数S使得对训练数据集的所有实例数据$s(x, y)≥0$成立，这样特征总数$T(x, y)$可用S代替。

于是我们可以将$t_k$和$s_l$的更新方程转变为：
$$
\sum_{x， y} \tilde{P}(x) P(y \mid x) \sum_{i=1}^{n+1} t_{k}\left(y_{i-1}， y_{i}， x， \quad i\right) \exp \left(\delta_{k} S\right)=E_{\tilde p}\left[t_{k}\right]  \\ 
\delta_{k}=\frac{1}{S} \log \frac{E_{\tilde p}\left[t_{k}\right]}{E_{P}\left[t_{k}\right]}  \\
E_{P}\left(t_{k}\right)=\sum_{x} \tilde{P}(x) \sum_{i=1}^{n+1} \sum_{y_{i-1}， y_{i}} t_{k}\left(y_{i-1}， y_{i}， x， i\right) \frac{\alpha_{i-1}^{\mathrm{T}}\left(y_{i-1} \mid x\right) M_{i}\left(y_{i-1}， y_{i} \mid x\right) \beta_{i}\left(y_{i} \mid x\right)}{Z(x)} 
$$

$$
\sum_{x， y} \tilde{P}(x) P(y \mid x) \sum_{i=1}^{n} s_{l}\left(y_{i}， x， \quad i\right) \exp \left(\delta_{K_{1}+l} S\right)=E_{\tilde p}\left[s_{l}\right]  \\
\delta_{K_{1}+l}=\frac{1}{S} \log \frac{E_{\tilde P}\left[s_{l}\right]}{E_{P}\left[s_{l}\right]}  \\
E_{P}\left(s_{l}\right)=\sum_{x} \tilde{P}(x) \sum_{i=1}^{n} \sum_{y_{i}} s_{l}\left(y_{i}， x， i\right) \frac{\alpha_{i}^{\mathrm{T}}\left(y_{i} \mid x\right) \beta_{i}\left(y_{i} \mid x\right)}{Z(x)} 
$$

在IIS算法中，如果$f_k(x, y)$，这里的$T(x, y)$为常数，则可以直接求得更新量，因为这里直接使用了常数S代替$T(x, y)$，因此也可以直接求更新量，这样的算法叫做算法S。



# 预测问题

条件随机场的预测问题是给定条件随机场P(Y|X）和输入序列（观测序列）x，求条件概率最大的输出序列（标记序列）y，即对观测序列进行标注。

## 维特比算法

首先给出条件随机场模型：
$$
P_{w}(y \mid x)=\frac{\exp (w \cdot F(y， x))}{Z_{w}(x)} 
$$
其中：
$$
w=\left(w_{1}， w_{2}， \cdots， w_{K}\right)^{\mathrm{T}} \\F(y， x)=\left(f_{1}(y， x)， f_{2}(y， x)， \cdots， f_{K}(y， x)\right)^{\mathrm{T}}  \\f_{k}(y， x)=\sum_{i=1}^{n} f_{k}\left(y_{i-1}， y_{i}， x， i\right)， k=1，2， \cdots， K 
$$
要得到新输入实例的标注$y^*$，需要让$P_w(y|x)$最大：
$$
\begin{aligned} 
y^{*} &=\arg \max _{y} P_{w}(y \mid x) \\
&= \arg \max _{y} \frac{\exp (w \cdot F(y， x))}{Z_{w}(x)} \\
&= \arg \max _{y} \arg \max _{y}(w \cdot F(y， x)) \\ 
&=\arg (y， x)) \end{aligned} 
$$
$Z_w(x)$是规范化因子，为常数，exp对最大化没有影响，都可以不考虑，因此只需要最大化$w·F(y, x)$就行了。

于是，条件随机场的预测问题成为求非规范化概率最大的最优路径问题：
$$
\max _{y}(w \cdot F(y， x)) 
$$
为了方便，我们将上式改为下面的形式：
$$
\max _{y} \sum_{i=1}^{n} w \cdot F_{i}\left(y_{i-1}， y_{i}， x\right) 
$$
其中：
$$
F_{i}\left(y_{i-1}， y_{i}， x\right)=\left(f_{1}\left(y_{i-1}， y_{i}， x， i\right)， f_{2}\left(y_{i-1}， y_{i}， x， i\right)， \cdots， f_{K}\left(y_{i-1}， y_{i}， x， i\right)\right)^{\mathrm{T}}
$$
是局部特征向量。因为在Fi中，仅包含两个结点y(i-1)和yi，所以叫局部特征向量。结点的遍历放在了外面。

现在维特比算法已万事俱备，我们来看看如何利用它来进行标注。

首先求出位置1的各个标记$j=1, 2,\cdots, m$的非规范化概率：
$$
\delta_{1}(j)=w \cdot F_{1}\left(y_{0}=\right. $start $ \left.， y_{1}=j， x\right)， \quad j=1，2， \ldots， m 
$$
这里做一个说明，在上式中仅考虑位置1，即$y_1$代表的位置。在$F_1$中，是对$y_1$进行了不同的特征函数的判断，因为一共有K个特征函数，所以需要判断K次，最后与特征向量w点乘算内积。因为在最大化的部分我们已经说明不考虑规范化因子Z，因此这里算出来的是非规范化概率。

由递推公式，可以求出每个位置的各个标记的非规范化概率，并得到每个位置所有标记的非规范化概率的最大值：
$$
\delta_{i}(l)=\max _{1 \leqslant j \leqslant m}\left\{\delta_{i-1}(j)+w \cdot F_{i}\left(y_{i-1}=j， y_{i}=l， x\right)\right\}，l=1， 2，  \cdots，  m 
$$
同时记录非规范化概率最大值的路径：
$$
\Psi_{i}(l)=\arg \max _{1 \leqslant j \leqslant m}\left\{\delta_{i-1}(j)+w \cdot F_{i}\left(y_{i-1}=j， y_{i}=l，x\right)\right\}， \quad l=1，2， \cdots， m 
$$
遍历所有位置1到n后，可以得到非规范化概率最大值：
$$
\max _{y}(w \cdot F(y， x))=\max _{1 \leqslant j \leqslant m} \delta_{n}(j) 
$$
和最优路径终点：
$$
y_{n}^{*}=\arg \max _{1 \leqslant j \leqslant m} \delta_{n}(j) 
$$
从最优路径终点返回往第一个位置依次得到每个位置的标记：
$$
y_{i}^{*}=\Psi_{i+1}\left(y_{i+1}^{*}\right)， i=n-1， n-2，  \cdots， 1
$$
得到最优路径：
$$
y^{*}=\left(y_{1}^{*}， y_{2}^{*}， \cdots， y_{n}^{*}\right)^{\mathrm{T}}
$$
