# 隐马尔可夫模型

了解隐马尔可夫模型前，先说一下**马尔可夫性**：在某个时刻$t\geq 1$的随机变量$X_t$与前一个时刻的随机变量$X_{t-1}$之间有条件分布$P(X_t|X_{t-1})$， 如果$X_t$只依赖于$X_{t-1}$ ，而不是依赖于过去的随机变量 $\{X_i,X_2, \cdots ,X_{t-2}\}$，这一性质称为马尔可夫性，即：
$$
P(X_t|X_i,X_2, \cdots ,X_{t-1}) = P(X_t|X_{t-1}),t=1,2, \cdots
$$


马尔可夫性，可以通俗的理解为：现在决定未来，而与过去无关。



**马尔科夫链**：在t时刻发生的事与t-1时刻发生的事件有关，即t时刻事件与t-1时刻事件不是互相独立的，并且t时刻发生的事也会对t+1时刻的事产生影响，我们可以认为上述的多个按时间顺序发生的非独立事件形成了马尔可夫链。

**马尔可夫过程**：上面的是离散时间马尔可夫链，因为其时间是离散的，对于时间连续的马尔可夫链，我们称之为马尔可夫过程。



# 隐马尔可夫模型

设$Q$是所有可能的状态的集合，$V$是所有可能的观测的集合：
$$
Q=\{q_1,q_2, \cdots ,q_M\},V=\{v_1,v_2, \cdots, v_1 \}
$$
$N$是可能的状态数，$M$是可能的观测数。

$I$是长度为$T$的状态序列，$O$是对应的观测序列：
$$
I=(i_1,i_2, \cdots, i_T),O=(o_1,o_2, \cdots, o_T)
$$
$A$是状态转移概率矩阵：
$$
A=[a_{ij}]_{N \times N }
$$
其中：
$$
a_{ij}=P(i_{t+1}=q_j|i_t=q_i),i=1,2, \cdots, N;j=1,2, \cdots, N
$$
是在时刻t处于状态$q_i$的条件下在时刻$t+1$转移到状态$q_j$的概率。



$B$是观测概率矩阵：
$$
B=[b_j(k)]_{N \times M}
$$
其中：
$$
b_j(k)=P(o_t=v_k|i_j=q_j),k=1,2, \cdots,M;j=1,2,\cdots,N
$$
是在时刻$t$处于状态$q$，的条件下生成观测$v_k$的概率。
$\pi$是初始状态概率向量：
$$
\pi = (\pi_i)
$$
其中，
$$
\pi_i=P(i_i=q_i),i=1,2,\cdots,N
$$
是时刻$t=1$处于状态$q$，的概率.
隐马尔可夫模型由初始状态概率向量$\pi$、状态转移概率矩阵$A$和观测概率矩
阵$B$决定。$\pi$和$A$决定状态序列，$B$决定观测序列。因此，隐马尔可夫模型$\lambda$可
以用三元符号表示，即
$$
\lambda = (A,B,\pi)
$$
$A,B,\pi$称为隐马尔可夫模型的三要素。



# 隐马尔可夫链模型的假设

1. 齐次马尔可夫性假设，即假设隐藏的马尔可夫链在任意时刻t的状态只依赖于其前一时刻的状态，与其他时刻的状态及观测无关，也与时刻t无关：

$$
P(i_t|i_{t-1},o_{t-1}, \cdots , i_1, o_i) = P(i_i|i_{i-1}), t=1,2, \cdots,T
$$

2. 观测独立性假设，即假设任意时刻的观测只依赖于该时刻的马尔可夫链的状态，与其他观测及状态无关：
   $$
   P(o_i|i_T,oT,i_{T-1},o_{T-1}, \cdots, i_{t+1},o_{t+1},i_{t},o_t,i_{t-1},o_{t-1}, \cdots ,i_1,o_1) = P(o_t|i_t)
   $$
   

# 隐马尔可夫模型学习的基本步骤

1. 计算概率。给定模型 $\lambda = (A,B,\pi)$ 和观测序列$O=(o_1,o_2, \cdots, o_T)$，计算在模型$\lambda$下观测序列$O$出现的概率$P(O|\lambda)$。

2. 学习问题。已知观测序列，估计模型参数，使得在该模型下观测序列概率最大，即用极大似然估计的方法估计参数。

3. 预测问题，也称为解码问题。已知模型和观测序列，求对给定观测序列条件概率P(I|O）最大的状态序列I。即给定观测序列，求最有可能的对应的状态序列。

   

# 概率计算算法

书中介绍了三种方法：

* 直接计算法
* 向前算法
* 向后算法



## 直接计算法

最直接的方法是按概率公式直接计算.通过列举所有可能的长度为T的状态序列$I=(i_1,i_2, \cdots, i_T)$，求各个状态序列$I$与观测序列$O=(o_1,o_2, \cdots, o_T)$的联合概率$P(O,I|\lambda)$，然后对所有可能的状态序列求和，得到$P(O|\lambda)$。



## 向前算法

前向算法是一种使用前向概率来达到使用较少的计算量就能够算出$P(O|\lambda)$的算法，首先我们需要定义什么是前向概率。

前向概率为给定隐马尔可夫模型$\lambda$，在时刻$t$，观测序列为$o_1, o_2, \cdots, o_t$且状态为$q_i$的概率：
$$
a_t(i)=P(o_1, o_2, \cdots, o_t， i_t=q_i| \lambda)
$$
通过前向概率推导得到$P(O|\lambda)$的步骤有三步：

1. 初值：

$$
a_1(i)=\pi_ib_i(o_1),i=1,2, \cdots,N
$$

$α_1(i)$为时刻$t=1$时，观测序列为$o_1$，且状态为$q_i$的概率。等式右边的$\pi_i$为初始状态概率向量中$q_i$的概率，$bi(o1)$表示状态为$qi$时，观测为$o_1$的概率。

记住，此时状态$q_i$是固定的，我们在最后将对所有的状态进行加和。

2. 递推，对$t=1,2, \cdots, T-1$:
   $$
   a_{t+1}(i)=[\sum_{j=1}^Na_t(j)a_{ji}]b_i(o_{t+1}), i=1,2, \cdots,N
   $$
   

计算到时刻$t+1$部分观测序列为$o_1,o_2, \cdots, o_t$且在时刻$t+1$处于状态$q_i$的前向概率。

公式中方括弧里，既然心$a_t(j)$是到时刻$t$观测到$o_1,o_2, \cdots, o_t$并在时刻$t$处于状态$q_j$的前向概率，那么乘积$a_t(j)a_{ji}$就是到时刻t观测到$o_1,o_2, \cdots, o_t$并在时刻$t$处于状态$q_j$而在时刻$t+1$到达状态$q_i$的联合概率。对这个乘积在时刻t的所有可能的$N$个状态$q_j$求和，其结果就是到时刻$t$观测为$o_1,o_2, \cdots, o_t$并在时刻￥t+1￥处于状态$q_i$的联合概率。方括弧里的值与观测概率$b_i(o_{t+1})$的乘积恰好是到时刻$t+1$观测到$o_1,o_2, \cdots, o_t, o_{t+1}$并在时刻$t+1$处于状态$q_i$的前向概率$a_{t+1}(i)$。



3. 终止
   $$
   P(O|\lambda) = \sum_{i=1}^Na_T(i)
   $$
   

其中$α_T(i)$为在最后时刻，整个观测序列已知的情况下，状态为$q_i$的概率。此时再将在最后时刻，状态为所有可能状态的概率相加，即得到在模型已知情况下，得到已知观测序列的概率。

计算时刻$t+1$的某一个状态时，已经将之前所有的状态的可能性相加了，也就是递推公式中括号内的求和项，如下图所示：

![image-20240227201931404](.\images\10.1.png)

上图只考虑了时刻$t+1$的一个状态，如果我们将所有的状态都考虑进去，则是：

![image-20240227203304466](.\images\10.2.png)

我们将图中的结构叫做观测序列路径结构。这种结构在每一次计算时，可以直接引用前一个时刻的计算结果，如此就避免了直接计算法中的重复计算。前向算法的时间复杂度为$O(T*N^2)$，远小于直接计算法的$O(T*N^T)$。

## 后向算法

给定隐马尔可夫模型$\lambda$，在时刻$t$状态为$q_i$的条件下，从$t+1$到$T$的部分观测序列为$o_{t+1}, o_{t+2}, \cdots, o_T$的概率为后向概率：
$$
\beta_t(i)=P($o_{t+1}, o_{t+2}, \cdots, o_T|i_t=q_i,\lambda)
$$
通过后向概率推导$P(O|\lambda)$同样有三步。

首先，我们对最终时刻的所有状态$q_i$规定$\beta_t(i)=1, i=1,2, \cdots , N$。

接着，对$t=T-1,T-2, \cdots , 1$：
$$
\beta_t(i)= = \sum_{j=1}^Na_{ij}b_j(o_{t+1})\beta_{t+1}(j),i=1,2, \cdots,N
$$
为了计算在时刻$t$状态为$q_i$，条件下时刻$t+1$之后的观测序列为$o_{t+1},o_{t+2}, \cdots , o_T$的后向概率$\beta_t(i)$，只需考虑在时刻$t+1$所有可能的$N$个状态$q_j$，的转移概率（即$a_{ij}$项），以及在此状态下的观测$o_{t+1}$的观测概
率（即$b_j(o_{t+1})$项），然后考虑状态$q_j$，之后的观测序列的后向概率（即$\beta_{t+1}(j)$项)。

最后：
$$
P(O \mid \lambda)=\sum_{i=1}^{N} \pi_{i} b_{i}\left(o_{1}\right) \beta_{1}(i) 
$$


# 学习算法

隐马尔可夫模型的学习，根据训练数据是包括观测序列和对应的状态序列还是只有观测序列，可以分别由监督学习与无监督学习实现。



## 监督学习方法

假设已给训练数据包含S个长度相同的观测序列和对应的状态序列${(O_1,I_1), (O_2,I_2), \cdots , (O_s,I_s)}$，那么可以利用极大似然估计法来估计隐马尔可夫模型的参数。具体方法如下：

1. 转移概率$a_{ij}$的估计

   设样本中时刻$t$处于状态$i$，且时刻$t+1$转移到状态j的频数为$A_{ij}$，那么状态转移概率$a_{ij}$的估计是：
   $$
   \hat{a}_{ij}=\frac{A_{ij}}{\sum_{j=1}^{N} A_{ij}}， i=1, 2， \cdots, N ; j=1, 2, \cdots, N 
   $$
   
2. 观测概率$b_j(k)$的估计

​		设样本中状态为$j$并观测为$k$的频数是$B_{jk}$，那么状态为$j$观测为$k$的概率$b_j(k)$的估计是：
$$
\\\hat{b}_{j}(k)=\frac{B_{j k}}{\sum_{k=1}^{M} B_{j k}}, j=1,2, \cdots, N ; k=1,2, \cdots, M 
$$

3. 初始状态概率$\pi_i$的估计$\hat\pi_i$为$S$个样本中初始状态为$q_i$的频率。

   在监督学习方法中，对三个参数的估计很简单，直接按照上面三个式子计算就可以了。但是现实情况中往往是没有标记的，其状态序列往往是隐变量，此时就需要用到无监督学习的方法。

## Baum-Welch算法

在隐马尔可夫模型中，状态序列未知，即为隐变量，那么就需要用到EM算法。根据EM算法，第一步，我们需要确定完全数据的形式：
$$
(O， I)=\left(o_{1}， o_{2}， \cdots， o_{T}， i_{1}， i_{2}， \cdots， i_{T}\right) "
$$
完全数据形式为包含每一时刻的状态和观测。

第二步，确定它的对数似然函数：
$$
log P(O， I \mid \lambda) 
$$
即在模型给定的情况下，最终的数据形态为(O, I)的概率的对数形式。

第三步，即EM算法中的E步，求Q函数：

在EM算法的推导中，我们可以得到Q函数为：
$$
Q\left(\theta， \theta^{(i)}\right)=\sum_{Z} P\left(Z \mid Y， \theta^{(i)}\right) \log P(Y， Z \mid \theta)
$$
其中$Z$为隐变量，$Y$为观测变量，$\theta(i)$为模型当前参数，$\theta$为我们在M步最大化的步骤中要优化的模型参数。

首先将其转换为隐马尔可夫模型中的符号表示并变换一下形式：
$$
Q(\lambda， \bar{\lambda})=\sum_{I} \log P(O， I \mid \lambda) P(O \mid I， \bar{\lambda})=\sum_{I} \log P(O， I \mid \lambda) \frac{P(O， I \mid \bar{\lambda})}{P(I \mid \bar{\lambda})}
$$
其中分母项是常数，因此：
$$
Q(\lambda， \bar{\lambda})=\sum_{I} \log P(O， I \mid \lambda) P(O， I \mid \bar{\lambda})
$$
因为：
$$
P(O， I \mid \lambda)=\pi_{i_{1}} b_{i_{1}}\left(o_{1}\right) a_{i_{1} i_{2}} b_{i_{2}}\left(o_{2}\right) \cdots a_{i_{T-1} i_{T}} b_{i_{T}}\left(o_{T}\right)
$$
我们将其中$\pi$，$a$和$b$的部分拆开，这样$Q$函数就可以写成：
$$
\begin{aligned} Q(\lambda， \bar{\lambda})=\sum_{I} \log \pi_{i_{1}} P(O，&I \mid \bar{\lambda})+\sum_{I}\left(\sum_{t=1}^{T-1} \log a_{i_{t} i_{t+1}}\right) P(O， I \mid \bar{\lambda})+  \sum_{I}\left(\sum_{t=1}^{T} \log b_{i_{t}}\left(o_{t}\right)\right) P(O， I \mid \bar{\lambda}) \end{aligned} 
$$
最后，EM算法的M步，极大化$Q$函数求模型参数。

因为在上一步中，我们已经把$\pi$，$a$和$b$的部分拆开了，单独地出现在三个项中，所以只需要对每个项分开来极大化就可以了。

对于$\pi$，我们只看第一项，第一项可以写成：
$$
\sum_{I} \log \pi_{i_{1}} P(O， I \mid \bar{\lambda})=\sum_{i=1}^{N} \log \pi_{i} P\left(O， i_{1}=i \mid \bar{\lambda}\right)
$$
其中$i_1$的下标1代表在$t=1$时刻的状态。

因为$\sum_{i=1}^{N} \pi_{i}=1 $，可以利用拉格朗日乘子法求最优，我们将拉格朗日函数求偏导并令其为0：
$$
 \frac{\partial}{\partial \pi_{i}}\left[\sum_{i=1}^{N} \log \pi_{i} P\left(O， i_{1}=i \mid \bar{\lambda}\right)+\gamma\left(\sum_{i=1}^{N} \pi_{i}-1\right)\right]=0
$$
得到：
$$
\frac{P\left(O， i_{1}=i \mid \bar{\lambda}\right)}{\pi_{i}}+\gamma=0 \rightarrow P\left(O， \quad i_{1}=i \mid \bar{\lambda}\right)+\gamma \pi_{i}=0 
$$
对i求和
$$
\gamma=-P(O \mid \bar{\lambda})
$$
再将其代入求导式中，得到：
$$
\pi_{i}=\frac{P\left(O， i_{1}=i \mid \bar{\lambda}\right)}{P(O \mid \bar{\lambda})}
$$
同样的步骤对后两项构建拉格朗日函数，求导并令其为0，可以得到：
$$
\begin{aligned} a_{i j} &=\frac{\sum_{t=1}^{T-1} P\left(O， i_{t}=i， i_{t+1}=j \mid \bar{\lambda}\right)}{\sum_{t=1}^{T-1} P\left(O， i_{t}=i \mid \bar{\lambda}\right)} \\ b_{j}(k) &=\frac{\sum_{t=1}^{T} P\left(O， i_{t}=j \mid \bar{\lambda}\right) I\left(o_{t}=v_{k}\right)}{\sum_{t=1}^{T} P\left(O， i_{t}=j \mid \bar{\lambda}\right)} \end{aligned}
$$
其中$b_j(k)$分子上的$I(o_t=v_k)$项为指数函数项，说明仅当t时刻的观测为$v_k$时指数函数为1。

现在M步结束，不过参数更新公式中的P应该如何算呢？

首先看$\pi_i$：
$$
\pi_{i}=\frac{P\left(O， i_{1}=i \mid \bar{\lambda}\right)}{P(O \mid \bar{\lambda})}=\frac{\alpha_{1}(i) \beta_{1}(i)}{P(O \mid \lambda)}=\frac{\alpha_{1}(i) \beta_{1}(i)}{\sum_{j=1}^{N} \alpha_{t}(j) \beta_{t}(j)}=\gamma_{1}(i)
$$


在上式中的分子部分，使用了前向概率和后向概率的定义。最后我们让其等于$\gamma_{1}(i)$，其中$\gamma$的下标1代表在$t=1$时刻，那么更一般的$\gamma_{t}(i)$为：
$$
\gamma_{t}(i)=\frac{\alpha_{t}(i) \beta_{t}(i)}{\sum_{j=1}^{N} \alpha_{t}(j) \beta_{t}(j)}
$$
再看$a_{ij}$：
$$
\begin{aligned}
a_{i j}&=\frac{\sum_{t=1}^{T-1} P\left(O， i_{t}=i， i_{t+1}=j \mid \bar{\lambda}\right)}{\sum_{t=1}^{T-1} P\left(O， i_{t}=i \mid \bar{\lambda}\right)} \\
&=\frac{\sum_{t=1}^{T-1} P\left(O， i_{t}=i， i_{t+1}=j \mid \bar{\lambda}\right)}{P(O \mid \bar{\lambda})} \frac{\sum_{t=1}^{T-1} P\left(O， i_{t}=i \mid \bar{\lambda}\right)}{P(O \mid \bar{\lambda})} \\ 
&=\frac{\sum_{t=1}^{T-1} P\left(O， i_{t}=i， i_{t+1}=j \mid \bar{\lambda}\right)}{P(O \mid \bar{\lambda}) \sum_{t=1}^{T-1} \gamma_{t}(i)} \\
&=\frac{\sum_{t=1}^{T-1} \xi_{t}(i， j)}{\sum_{t=1}^{T-1} \gamma_{t}(i)}
\end{aligned}
$$
其中我们让：
$$
\frac{P\left(O， i_{t}=i， i_{t+1}=j \mid \bar{\lambda}\right)}{P(O \mid \bar{\lambda})}=\xi_{t}(i， j)=\frac{\alpha_{t}(i) a_{i j} b_{j}\left(o_{t+1}\right) \beta_{t+1}(j)}{\sum_{i=1}^{N} \sum_{j=1}^{N} \alpha_{t}(i) a_{i j} b_{j}\left(o_{t+1}\right) \beta_{t+1}(j)}
$$
最后，$b_j(k)$：
$$
b_{j}(k)=\frac{\sum_{t=1}^{T} P\left(O， i_{t}=j \mid \bar{\lambda}\right) I\left(o_{t}=v_{k}\right)}{\sum_{t=1}^{T} P\left(O， i_{t}=j \mid \bar{\lambda}\right)}=\frac{\sum_{t=1，}^{T} o_{t}=v_{k} \gamma_{t}(j)}{\sum_{t=1}^{T} \gamma_{t}(j)} 
$$


# 预测算法

预测算法的前提是已经得到隐马尔可夫模型的三大元素的估计值。预测算法这里介绍近似算法和维特比算法。



## 近似算法

近似算法的想法是，在每个时刻t选择在该时刻最有可能出现的状态，从而得到一个状态序列$I^{*}=\left(i_{1}^{*}， i_{2}^{*}，\cdots， i_{T}^{*}\right) $作为预测的结果。

给定隐马尔可夫模型$\lambda$和观测序列$O$，在时刻t处于状态$q_i$的概率是：
$$
\gamma_{t}(i)=\frac{\alpha_{t}(i) \beta_{t}(i)}{\sum_{j=1}^{N} \alpha_{t}(j) \beta_{t}(j)}
$$
那么对于每一时刻t，最有可能的i是$\gamma_{t}(i)$取最大值对应的i：
$$
i_{t}^{*}=\arg \max _{1 \leqslant i \leqslant N}\left[\gamma_{t}(i)\right]， t=1， 2， \cdots， T 
$$
对每一时刻t进行上述计算，即可得到 $I^{*}$ 。

近似算法计算简单，但它只能得到局部的最优解，其整体状态序列可能不是全局最优的。



## 维特比算法

首先定义两个变量。

第一个变量：定义在时刻t状态为i的所有单个路径$(i_1, i_2, …, i_t)$中概率最大值为：
$$
\delta_{t}(i)=\max _{i_{1}， i_{2}， \cdots， i_{t-1}} P\left(i_{t}=i， i_{t-1}， \cdots， i_{1}， o_{t}， \cdots， o_{1} \mid \lambda\right)， i=1，2， \cdots， N
$$
它的递推公式为：
$$
\begin{aligned} \delta_{t+1}(i) &=\max _{i_{1}， i_{2}， \cdots， i_{t}} P\left(i_{t+1}=i， i_{t}， \cdots， i_{1}， o_{t+1}， \cdots， o_{1} \mid \lambda\right) \\ &=\max _{1 \leqslant j \leqslant N}\left[\delta_{t}(j) a_{j i}\right] b_{i}\left(o_{t+1}\right)， i=1，2， \cdots， N ； t=1，2， \cdots， T-1 \end{aligned}
$$
第二个变量：定义在时刻t状态为i的所有单个路径(i1, i2, …, i(t-1), i)中概率最大的路径的第t-1个结点为：
$$
\Psi_{t}(i)=\arg \max _{1 \leqslant j \leqslant N}\left[\delta_{t-1}(j) a_{j i}\right]， i=1， 2， \cdots， N
$$
为了便于理解，根据该定义举例，首先来看在$t=1$的情况下，我们使用$\pi_i$代替$\delta_{t}(j)a_{ij}$ ，即：
$$
\delta_{1}(i)=\pi_{i} b_{i}\left(o_{1}\right) 
$$
其中i即状态，$o_1$为$t=1$时的观测值$b_i(o_1)$为在状态i时观测值为$o_1$的概率，因为是初始状态，每一个$\delta_{1}(i)$只有一条路径，所以它的最大值就是$\pi_{i} b_{i}\left(o_{1}\right)$ 。

此时对于$\Psi_{1}(i)$来说，因为它求得是所有路径中概率最大得路径得第$t-1$个结点，此时$t=1$，因此$t-1=0$，$t=0$不在考虑范围内，所以我们规定$\Psi_{1}(i)=0$

现在考虑$t=2$的情况：
$$
\delta_{2}(i)=\max _{1 \leqslant j<N}\left[\delta_{1}(j) a_{j i}\right] b_{i}\left(o_{2}\right)
$$
首先看$max$项的内部 $\delta_{1}(i)$，为上一个时刻$t=1$时，状态为$j$的概率乘以由状态$j$转移至状态$i$的概率，因为在$t=1$时，我们已经将每一个状态的概率都计算了出来，因此这是可求的。

假设在状态集合中一共有3个状态，那么对于$t=2$时刻的一个特定状态，比如状态$q_1$来说，都需要计算一次从$t=1$时刻的状态$q_1，q_2，q_3$转移至该特定状态$q_1$的概率，然后取这三个概率中的最大值，并且乘以在$q_1$状态下观测值为$o_2$的概率。

那么对于$\Psi_{2}(i)$来说，对于每一个$t=2$时刻的状态，它的值是选择的最大值所对应的$t=1$时刻的状态。

比如：
$$
\delta_{2}(1)=\max _{1 \leqslant j \leqslant N}\left[\delta_{1}(1) a_{11} ； \delta_{1}(2) a_{21} ； \delta_{1}(3) a_{31}\right] b_{1}\left(o_{2}\right)
$$
在上式中$\delta_{1}(2)a_{21}$是最大的，那么$\Psi_{2}(1)=2$ ，因为这个最大值对应的是第二个状态。

这样按照时间顺序递推，可以得到$\Psi_{t}(1)， \mathrm{t}=1，2， \cdots， \mathrm{T}$，最后，根据：

$i_{t}^{*}=\Psi_{t+1}\left(i_{t+1}^{*}\right)$

从后往前求得最优路径$ I^{*}=\left(i_{1}^{*}， i_{2}^{*}， \cdots， i_{T}^{*}\right) $ 。